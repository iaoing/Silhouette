'''
Obtain the unique test cases from memcached, and construct the corresponding
test cases for Silhouette.
'''
import os
import sys
import argparse
import time
import time
import glob
import re
import ast
import memcache
import inspect

codebase_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), "../.."))
sys.path.append(codebase_dir)

from scripts.fs_conf.base.env_base import EnvBase
from scripts.fs_conf.nova.env_nova import EnvNova
from scripts.utils.utils import dirExists, dirEmpty, mkdirDir
import scripts.utils.logger as log

# Maps j-lang generic operations to NOVA/PMFS/WineFS's operations
# Thus information could be obtained by visit 'file_operations', 'inode_operations', etc., from AST.
# For simplicity, just hard-coded here.
FSOpDict = {
    'write' : ['nova_dax_file_write', 'pmfs_xip_file_write'],
    'creat' : ['nova_create', 'nova_get_link', 'pmfs_create', 'pmfs_get_link'],
    'umount' : ['nova_put_super', 'pmfs_put_super'],
    'mkdir' : ['nova_mkdir', 'pmfs_mkdir'],
    'falloc' : ['nova_fallocate', 'pmfs_fallocate'],
    'link' : ['nova_link', 'pmfs_link'],
    'unlink' : ['nova_unlink', 'pmfs_unlink'], # ace uses unlink to remove a file
    'rename' : ['nova_rename', 'pmfs_rename'],
    'truncate' : ['nova_notify_change', 'pmfs_notify_change'],
    'symlink' : ['nova_symlink', 'pmfs_symlink'],
    'rmdir' : ['nova_rmdir', 'pmfs_rmdir'], # ace uses rmdir to remove a dir
}

# Thus information could be obtained by visit 'file_operations', 'inode_operations', etc., from AST.
# For simplicity, just hard-coded here.
InconsequentialOpsSet = {
    'nova_lookup',
    'nova_open',
    'nova_flush',
    'nova_readdir',
    'pmfs_readdir',
    'pmfs_lookup',
    'pmfs_getattr',
    'pmfs_flush',
    'pmfs_xip_file_read',
    'generic_file_open',
}

def parse_args():
    parser = argparse.ArgumentParser(description='my args')

    parser.add_argument("--test_case_dir", type=str,
                        required=True,
                        help='The directory that contains "j-lang-files" directory, which contains the ACE j-lang files.')
    parser.add_argument("--result_dir", type=str,
                        required=True,
                        help="The result directory of 'result_unique_ops' that is generated by 'codebase/scripts/executor/host_side/result_analysis/dump_all.sh'.")
    parser.add_argument("--output_case_dir", type=str,
                        required=True,
                        help='The directory for outputing newly constructed test cases.')
    parser.add_argument("--logging_file", type=str,
                        required=False, default='-',
                        help="The logging file")
    parser.add_argument("--logging_level", type=int,
                        required=False, default=40,
                        help="stderr output level:\n10: debug; 20: info ; 30: warning; 40: error; 50: critical. Default: 40.")
    parser.add_argument("--stderr_level", type=int,
                        required=False, default=40,
                        help="stderr output level:\n10: debug; 20: info ; 30: warning; 40: error; 50: critical. Default: 40.")

    args = parser.parse_args()
    print(args)

    logging_file = args.logging_file
    logging_level = args.logging_level
    stderr_level = args.stderr_level

    if logging_file != '-':
        log.setup_global_logger(fname=logging_file, file_lv=logging_level, stm_lv=stderr_level, stm=sys.stderr)
    else:
        log.setup_global_logger(stm_lv=stderr_level, stm=sys.stderr)

    return args

def check_args(args):
    test_case_dir = args.test_case_dir
    result_dir = args.result_dir
    test_j_lang_dir = test_case_dir + "/j-lang-files"
    output_case_dir = args.output_case_dir
    output_j_lang_dir = output_case_dir + "/j-lang-files"

    if not dirExists(test_case_dir):
        print(f"test_case_dir does not exist: {test_case_dir}", file=sys.stderr)
        exit(1)
    elif not dirExists(result_dir):
        print(f"result_dir does not exist: {result_dir}", file=sys.stderr)
        exit(1)
    elif not dirExists(test_j_lang_dir):
        print(f"test_case_dir's j-lang-files does not exist: {test_j_lang_dir}", file=sys.stderr)
        exit(1)

    if not dirExists(output_case_dir):
        mkdirDir(output_case_dir)
    if not dirExists(output_j_lang_dir):
        mkdirDir(output_j_lang_dir)
    elif not dirEmpty(output_j_lang_dir):
        print(f"output_case_dir's j-lang-files is not empty: {output_j_lang_dir}", file=sys.stderr)
        exit(1)

def timeit(func):
    """Decorator that prints the time a function takes to execute."""
    def wrapper(*args, **kwargs):
        start_time = time.perf_counter()
        result = func(*args, **kwargs)
        log.time_logger.info(f"elapsed_time.host.to_silhouette_workload.{func.__name__}:{time.perf_counter() - start_time}")
        return result
    return wrapper

def get_line_number():
    # Get the caller's frame and its line number
    frame = inspect.currentframe().f_back
    line_number = frame.f_lineno
    return line_number

def setup_env():
    # use env to get memcached IP and port.
    env = EnvNova()
    return env

# @timeit
# def get_unique_cases(memcached_client):
#     unique_test_cases = []
#     unique_case_count = 0
#     while True:
#         unique_case_count += 1
#         key = f'dedup.unique.{unique_case_count}'
#         value = memcached_client.get(key)
#         if not value:
#             break
#         # print(f'key: {key}, value: {str(value)}')
#         # value: ['j-langxxx', ['op1', 'op2', ..., 'op-target']]
#         unique_test_cases.append(value)
#     return unique_test_cases

@timeit
def get_unique_cases(result_dir):
    unique_test_cases = []
    for fpath in glob.glob(f'{result_dir}/unique*.txt'):
        print(fpath)

        fd = open(fpath, 'r')
        lines = fd.readlines()
        fd.close()

        j_file = None
        op_list = None
        for line in lines:
            line = line.strip()
            if line.startswith('basename: '):
                j_file = line[len('basename: '):]
                # print(j_file)
            elif j_file and line.startswith('['):
                op_list = ast.literal_eval(line)
                unique_test_cases.append([j_file, op_list])
                j_file = None
                op_list = None

    return unique_test_cases

@timeit
def get_j_lang_files(j_file_dir):
    # j-file number to j-file path
    j_file_dict = dict()
    for fpath in glob.glob(j_file_dir + "/*"):
        match = re.search(r'\d+', os.path.basename(fpath))
        if not match:
            print(f"Not a valid j-lang file: {fpath} in {j_file_dir}")
        else:
            j_file_dict[int(match.group())] = fpath
    return j_file_dict

def read_j_file(fpath):
    lines = None
    with open(fpath, 'r') as fd:
        lines = fd.readlines()
    return lines

def construct_new_j_file_content(op_list, j_file_path):
    new_lines = []
    lines = read_j_file(j_file_path)
    op_idx = 0
    ln_idx = 0
    begin_run = False
    while ln_idx < len(lines):
        skip_line = False
        line = lines[ln_idx]
        if op_idx >= len(op_list):
            break
        elif line.startswith('# run'):
            begin_run = True
        elif begin_run:
            while op_idx < len(op_list):
                if op_list[op_idx] in InconsequentialOpsSet:
                    op_idx += 1
                else:
                    break

            if line.isspace():
                pass
            elif line.startswith('mark') or line.startswith('none') or line.startswith('checkpoint'):
                # some ops designed for ACE only
                pass
            elif line.startswith('close') or line.startswith('opendir'):
                # close, opendir, and readdir, write nothing to PM
                pass
            elif line.startswith('open') and 'O_CREAT' in line:
                if op_list[op_idx] in FSOpDict['creat']:
                    op_idx += 1
                else:
                    # may creating an existing file, may creating an existing symlink
                    # manually check it when see this msg
                    print(f"WARNING @{get_line_number()}: unknown unique op: [{op_list[op_idx]}], {str(op_list)}, {j_file_path}")
                    # op_idx += 1
            elif line.startswith('mkdir'):
                if op_list[op_idx] in FSOpDict['mkdir']:
                    op_idx += 1
                else:
                    print(f"WARNING @{get_line_number()}: unknown unique op: [{op_list[op_idx]}], {str(op_list)}, {j_file_path}")
                    op_idx += 1
            elif line.startswith('write') or line.startswith('dwrite'):
                if op_list[op_idx] in FSOpDict['write']:
                    op_idx += 1
                else:
                    print(f"WARNING @{get_line_number()}: unknown unique op: [{op_list[op_idx]}], {str(op_list)}, {j_file_path}")
                    op_idx += 1
            elif line.startswith('falloc'):
                if op_list[op_idx] in FSOpDict['falloc']:
                    op_idx += 1
                else:
                    print(f"WARNING @{get_line_number()}: unknown unique op: [{op_list[op_idx]}], {str(op_list)}, {j_file_path}")
                    op_idx += 1
            elif line.startswith('link'):
                if op_list[op_idx] in FSOpDict['link']:
                    op_idx += 1
                else:
                    print(f"WARNING @{get_line_number()}: unknown unique op: [{op_list[op_idx]}], {str(op_list)}, {j_file_path}")
                    op_idx += 1
            elif line.startswith('unlink') or line.startswith('remove'):
                if op_list[op_idx] in FSOpDict['unlink']:
                    op_idx += 1
                else:
                    print(f"WARNING @{get_line_number()}: unknown unique op: [{op_list[op_idx]}], {str(op_list)}, {j_file_path}")
                    op_idx += 1
            elif line.startswith('rename'):
                if op_list[op_idx] in FSOpDict['rename']:
                    op_idx += 1
                else:
                    print(f"WARNING @{get_line_number()}: unknown unique op: [{op_list[op_idx]}], {str(op_list)}, {j_file_path}")
                    op_idx += 1
            elif line.startswith('truncate'):
                if op_list[op_idx] in FSOpDict['truncate']:
                    op_idx += 1
                else:
                    print(f"WARNING @{get_line_number()}: unknown unique op: [{op_list[op_idx]}], {str(op_list)}, {j_file_path}")
                    op_idx += 1
            elif line.startswith('symlink'):
                if op_list[op_idx] in FSOpDict['symlink']:
                    op_idx += 1
                else:
                    print(f"WARNING @{get_line_number()}: unknown unique op: [{op_list[op_idx]}], {str(op_list)}, {j_file_path}")
                    op_idx += 1
            elif line.startswith('rmdir'):
                if op_list[op_idx] in FSOpDict['rmdir']:
                    op_idx += 1
                else:
                    print(f"WARNING @{get_line_number()}: unknown unique op: [{op_list[op_idx]}], {str(op_list)}, {j_file_path}")
                    op_idx += 1
            else:
                print(f"WARNING @{get_line_number()}: unknown j-lang op: {line.rstrip()} in {j_file_path}")

        if skip_line:
            pass
        elif not begin_run or (not line.startswith('mark') and not line.startswith('none') and not line.startswith('checkpoint')):
            new_lines.append(line)
        ln_idx += 1

    # print(f"old:\n{lines}\nop:\n{op_list}\nnew:\n{lines[:ln_idx]}\n")
    return new_lines

@timeit
def build_test_case_for_silhouette(j_file_dict, unique_test_cases):
    new_j_file_dict = dict()
    for value in unique_test_cases:
        # value: ['j-langxxx', ['op1', 'op2', ..., 'op-target']]
        match = re.search(r'\d+', value[0])
        if not match:
            print(f"Not a valid j-lang file: {value[0]} in unique_test_cases")
        elif int(match.group()) not in j_file_dict:
            print(f"No such a j-lang file: {value[0]} in ace dir")
        else:
            j_file_num = int(match.group())
            j_file_content = construct_new_j_file_content(value[1], j_file_dict[j_file_num])
            if j_file_num not in new_j_file_dict:
                # since one j file could have more than one unique ops, use list to store them
                new_j_file_dict[j_file_num] = []
            new_j_file_dict[j_file_num].append(j_file_content)
    return new_j_file_dict

@timeit
def output_j_files(output_j_lang_dir, new_j_file_dict):
    for num, new_files in new_j_file_dict.items():
        for i in range(len(new_files)):
            fpath = f'{output_j_lang_dir}/j-lang-{num}-{i+1:02d}'
            with open(fpath, 'w') as fd:
                fd.writelines(new_files[i])

@timeit
def main(args):
    check_args(args)

    test_case_dir = args.test_case_dir
    result_dir = args.result_dir
    test_j_lang_dir = test_case_dir + "/j-lang-files"
    output_case_dir = args.output_case_dir
    output_j_lang_dir = output_case_dir + "/j-lang-files"

    unique_test_cases = get_unique_cases(result_dir)
    j_file_dict = get_j_lang_files(test_j_lang_dir)
    new_j_file_dict = build_test_case_for_silhouette(j_file_dict, unique_test_cases)
    output_j_files(output_j_lang_dir, new_j_file_dict)

if __name__ == "__main__":
    args = parse_args()
    main(args)
